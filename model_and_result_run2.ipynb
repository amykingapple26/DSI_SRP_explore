{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc82d3ad",
   "metadata": {},
   "source": [
    "# Run 1 : Data Split and Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b9504",
   "metadata": {},
   "source": [
    "## Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pacakges\n",
    "\n",
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = '4'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = '4'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '4'\n",
    "\n",
    "## for data process\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "import math\n",
    "\n",
    "## for plotting\n",
    "from sktime.utils.plotting import plot_series\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "## for machine learning\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "## for deep learning\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D,Flatten\n",
    "\n",
    "## for performance measurement\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "## for warnings\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "simplefilter(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76865383",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf7ba13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77fc480",
   "metadata": {},
   "source": [
    "## 2. Common functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72f84b",
   "metadata": {},
   "source": [
    "### (1) Define X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf24c6b",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "* y (pd.Series) – Target series\n",
    "\n",
    "* X (pd.DataFrame, optional (default=None)) – Exogenous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_X_y(df, ticker, exogenous_list):\n",
    "    data = df[df['ticker'] == ticker]\n",
    "    \n",
    "    if len(exogenous_list) == 1:\n",
    "        X = data[exogenous_list].to_frame()\n",
    "        \n",
    "    else:\n",
    "        X = data[exogenous_list]\n",
    "    \n",
    "    y = data['Return_group']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8718cdde",
   "metadata": {},
   "source": [
    "### (2) For Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27562fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: split dataset into train and test\n",
    "# n: number of predictions\n",
    "# X: Exogenous data, predicting variables\n",
    "# y: Target series\n",
    "\n",
    "def split_n (n, X, y):\n",
    "    \n",
    "    if n == 1:\n",
    "        y_train, y_test, X_train, X_test = temporal_train_test_split( y = y, X = X, test_size = 1)\n",
    "    \n",
    "    else:\n",
    "        y_train, y_test, X_train, X_test = temporal_train_test_split( y = y[:(-n+1)], X = X[:(-n+1)],test_size = 1)\n",
    "    \n",
    "    return y_train, y_test, X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: fit model to the dataset\n",
    "# y_train: training set for y\n",
    "# y_test: test set for y\n",
    "# X_train: training set for X\n",
    "# X_test: test set for X\n",
    "# model_name_and_param: model name and its corresponding parameters\n",
    "\n",
    "def model(y_train, y_test, X_train, X_test, model_name_and_param):\n",
    "    \n",
    "    # define model\n",
    "    model = model_name_and_param\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluate predictions\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return acc, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e0c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: get one-step forecast and iterate the process for n times\n",
    "# n: number of predictions\n",
    "# X: Exogenous data, predicting variables\n",
    "# y: Target series\n",
    "# model_name_and_param: model name and its corresponding parameters\n",
    "\n",
    "def pred_n(n, X, y, model_name_and_param):\n",
    "    \n",
    "    y_test_all = y[-n:]\n",
    "    y_pred_all = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        y_train = split_n((n-i), X, y)[0]\n",
    "        y_test = split_n((n-i), X, y)[1]\n",
    "        X_train = split_n((n-i), X, y)[2]\n",
    "        X_test = split_n((n-i), X, y)[3]\n",
    "    \n",
    "        y_pred = model(y_train, y_test, X_train, X_test, model_name_and_param)[1]\n",
    "        y_pred_all.append(y_pred)\n",
    "    \n",
    "    return y_test_all, y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: display the predction results\n",
    "# n: number of predictions\n",
    "# X: Exogenous data, predicting variables\n",
    "# y: Target series\n",
    "# model_name_and_param: model name and its corresponding parameters\n",
    "def result(n, X, y, model_name_and_param):\n",
    "    \n",
    "    # y_test\n",
    "    y_test_all = pred_n(n, X, y, model_name_and_param)[0]\n",
    "    y_test_list = y_test_all.tolist()\n",
    "    \n",
    "    # y_pred\n",
    "    y_pred_all = pred_n(n, X, y, model_name_and_param)[1]\n",
    "    \n",
    "    \n",
    "    # get accuracy_score\n",
    "    acc = accuracy_score(y_test_all, y_pred_all)\n",
    "\n",
    "    # get result\n",
    "    result = pd.DataFrame(y_pred_all, columns = ['y_pred'])\n",
    "    result['y_test'] = y_test_list\n",
    "    \n",
    "    return acc, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee1f5c1",
   "metadata": {},
   "source": [
    "### (3) For deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: split dataset into train and test; scale and standardize the data\n",
    "# n: number of predictions\n",
    "# X: Exogenous data, predicting variables\n",
    "# y: Target series\n",
    "\n",
    "def dl_split_n(n, X, y):\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    \n",
    "    if n == 1:\n",
    "        y_train, y_test, X_train, X_test = temporal_train_test_split( y = y, X = X, test_size = 1)\n",
    "    \n",
    "    else:\n",
    "        y_train, y_test, X_train, X_test = temporal_train_test_split( y = y[:(-n+1)], X = X[:(-n+1)],test_size = 1)\n",
    "    \n",
    "    # convert y to categorial\n",
    "    y_train = to_categorical(y_train,3)\n",
    "    y_test = to_categorical(y_test,3)\n",
    "    \n",
    "    # scale the train and test set for X\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    return y_train, y_test, X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3adbc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Classification, Conv1D layer\n",
    "# Input --> Conv --> Max Pooling --> softmax --> Classification\n",
    "\n",
    "# RNN and LSTM\n",
    "# Input --> Embedding --> Bidirectional --> Dense --> Classification\n",
    "\n",
    "# function: fit model to the dataset\n",
    "# model_name: model name\n",
    "# y_train: training set for y\n",
    "# y_test: test set for y\n",
    "# X_train: training set for X\n",
    "# X_test: test set for X\n",
    "\n",
    "def dl_model(model_name, y_train, y_test, X_train, X_test):\n",
    "    \n",
    "    # initialize the constructor\n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    # reshape data\n",
    "    var_num = X_train.shape[1]\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    \n",
    "    # design model\n",
    "    if model_name == 'CNN':\n",
    "        model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape = (X_train.shape[1],1)))\n",
    "        model.add(Dense(16, activation=\"relu\"))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(3, activation = 'softmax'))\n",
    "        \n",
    "    if model_name == 'RNN_LSTM':\n",
    "        model.add(Bidirectional(LSTM(units=128,input_shape=(X_train.shape[1],1))))\n",
    "        model.add(Dropout(rate=0.5))\n",
    "        model.add(Dense(units=128, activation='relu'))\n",
    "        model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=0)\n",
    "    \n",
    "    # predict y\n",
    "    y_pred = model(X_test)\n",
    "    pred_class = np.argmax(y_pred, axis = -1)\n",
    "    \n",
    "    return y_pred, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f229a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: display the predction results\n",
    "# n: number of predictions\n",
    "# X: Exogenous data, predicting variables\n",
    "# y: Target series\n",
    "# model_name: model name\n",
    "def dl_result(n, X, y, model_name):\n",
    "    \n",
    "    y_pred_all = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        y_train = dl_split_n(n-i, X, y)[0]\n",
    "        y_test = dl_split_n(n-i, X, y)[1]\n",
    "        X_train = dl_split_n(n-i, X, y)[2]\n",
    "        X_test = dl_split_n(n-i, X, y)[3]\n",
    "        \n",
    "        pred_class = dl_model(model_name, y_train, y_test, X_train, X_test)[1]\n",
    "        y_pred_all.append(pred_class[0])\n",
    "        \n",
    "    for i in range(len(y_pred_all)):\n",
    "        if y_pred_all[i] == 2:\n",
    "            y_pred_all[i] = -1\n",
    "    \n",
    "    result = pd.DataFrame(y_pred_all, columns = ['y_pred'])\n",
    "    y_test_all = y[-n:].tolist()\n",
    "    result['y_test'] = y_test_all\n",
    "    \n",
    "    # get accuracy_score\n",
    "    acc = accuracy_score(y_test_all, y_pred_all)\n",
    "    \n",
    "    return acc, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffe855",
   "metadata": {},
   "source": [
    "### (4) For portfolio simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4159781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: get the portfolio simulation dataset\n",
    "# n: number of prediction days\n",
    "# ticker: stock tickers to include\n",
    "# df: dataframe\n",
    "def mock_dataset(n, pred, ticker, df):\n",
    "    \n",
    "    simu = df[df['ticker'] == ticker]\n",
    "    \n",
    "    price_all = simu['PRC']\n",
    "    \n",
    "    price = simu[(len(price_all)-n-1):(len(price_all)-1)]['PRC'].tolist()\n",
    "    \n",
    "    mock = pd.DataFrame(price, columns = ['price'])\n",
    "    mock['y_pred'] = pred\n",
    "    \n",
    "        # create a list of our conditions\n",
    "    conditions = [\n",
    "        (mock['y_pred'] == -1),\n",
    "        (mock['y_pred'] == 0),\n",
    "        (mock['y_pred'] == 1)\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = ['sell', 'hold', 'buy']\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    mock['action'] = np.select(conditions, values)\n",
    "    \n",
    "    return mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: buy shares using all dollar amount\n",
    "# price: stock price at excuation\n",
    "# balance: account balance\n",
    "# share: number of shares in the account\n",
    "def buy(price, balance, share):\n",
    "    \n",
    "    share_change = math.floor(balance / price)\n",
    "    share += share_change\n",
    "    balance = balance - ( price * share_change)\n",
    "\n",
    "    return balance, share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44494544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: sell all shares in the account\n",
    "# price: stock price at excuation\n",
    "# balance: account balance\n",
    "# share: number of shares in the account\n",
    "def sell(price, balance, share):\n",
    "    \n",
    "    if share > 0:\n",
    "        balance_change = share * price\n",
    "        balance += balance_change\n",
    "        share = 0\n",
    "    \n",
    "    return balance, share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: hold (take no action)\n",
    "# price: stock price at excuation\n",
    "# balance: account balance\n",
    "# share: number of shares in the account\n",
    "def hold(price, balance, share):\n",
    "    \n",
    "    return balance, share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: simulate the portfolio actions\n",
    "# mock: the mock dataset\n",
    "def simulation(mock):\n",
    "    \n",
    "    balance = 1000000\n",
    "    beginning_balance = 1000000\n",
    "    share = 0\n",
    "    profit_or_loss = 0\n",
    "    total_value = 1000000\n",
    "    price = 0\n",
    "    \n",
    "    price_all = mock['price']\n",
    "    pred_all = mock['y_pred']\n",
    "    num = len(price_all)\n",
    "    \n",
    "    i = 0\n",
    "    while (i < num):\n",
    "        \n",
    "        price = price_all[i]\n",
    "        \n",
    "        if pred_all[i] == 1:\n",
    "            effect = buy(price, balance, share)\n",
    "        \n",
    "        elif pred_all[i] == -1:\n",
    "            effect = sell(price, balance, share)\n",
    "            \n",
    "        else:\n",
    "            effect = hold(price, balance, share)\n",
    "        \n",
    "        balance  = effect[0]\n",
    "        share  = effect[1]\n",
    "        \n",
    "        i = i + 1;\n",
    "    \n",
    "    # calculate final balance amount\n",
    "    if share == 0:\n",
    "        profit_or_loss = balance - beginning_balance\n",
    "        stock_return = (profit_or_loss / beginning_balance)\n",
    "    elif share > 0:\n",
    "        total_value = share * price + balance\n",
    "        profit_or_loss = total_value - beginning_balance\n",
    "        stock_return = (profit_or_loss / beginning_balance)\n",
    "    \n",
    "    return balance, share, profit_or_loss, stock_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a5e5c9",
   "metadata": {},
   "source": [
    "### (5) Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    try:\n",
    "        return '{0:.2%}'.format(x)\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(df, type):\n",
    "\n",
    "    df.loc['mean'] = df.mean()\n",
    "    df.loc['std'] = df[:-1].std()\n",
    "    mean = df.iloc[-2].tolist()\n",
    "    std = df.iloc[-1].tolist()\n",
    "    df = df.applymap(func)\n",
    "    \n",
    "    if type == 'portfolio':\n",
    "        risk_free_rate = 0.0093\n",
    "        sharpe_ratio = [float(\"{:.4f}\".format((m - risk_free_rate) / s)) for m, s in zip(mean, std)]\n",
    "        df.loc[\"sharpe_ratio\"] = sharpe_ratio\n",
    "        \n",
    "    df = df.replace(['nan%'],'NaN')   \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(df, n, ticker, exogenous_list, classifier_list):\n",
    "    \n",
    "    # store accuracy score\n",
    "    acc_list = [ticker]\n",
    "    \n",
    "    # store portfolio profit or loss\n",
    "    balance_list = [ticker]\n",
    "    \n",
    "    X = define_X_y(df, ticker, exogenous_list)[0]\n",
    "    y = define_X_y(df, ticker, exogenous_list)[1]\n",
    "    \n",
    "    for classifier in classifier_list[:9]:\n",
    "        outcome = result(n, X, y, classifier)\n",
    "        acc = outcome[0]\n",
    "        acc_list.append(acc)\n",
    "        \n",
    "        pred = outcome[1]['y_pred']\n",
    "        mock = mock_dataset(n, pred, ticker, df)\n",
    "        stock_return = simulation(mock)[3]\n",
    "        balance_list.append(stock_return)\n",
    "    \n",
    "    # for deep learning\n",
    "    outcome = dl_result(n,X,y,classifier_list[9])\n",
    "    acc_list.append(outcome[0])\n",
    "    pred = outcome[1]['y_pred']\n",
    "    mock = mock_dataset(n, pred, ticker, df)\n",
    "    stock_return = simulation(mock)[3]\n",
    "    balance_list.append(stock_return)\n",
    "    \n",
    "    outcome = dl_result(n,X,y,classifier_list[10])\n",
    "    acc_list.append(outcome[0])\n",
    "    pred = outcome[1]['y_pred']\n",
    "    mock = mock_dataset(n, pred, ticker, df)\n",
    "    stock_return = simulation(mock)[3]\n",
    "    balance_list.append(stock_return)\n",
    "    \n",
    "    return acc_list, balance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aca096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_combine(df, n, ticker_list, exogenous_list, classifier_list, model_list):\n",
    "    \n",
    "    acc_all = []\n",
    "    balance_all = []\n",
    "    \n",
    "    for ticker in ticker_list:\n",
    "        \n",
    "        table = apply(df, n, ticker, exogenous_list, classifier_list)\n",
    "        \n",
    "        acc_list = table[0]\n",
    "        acc_all.append(acc_list)\n",
    "        \n",
    "        balance_list = table[1]\n",
    "        balance_all.append(balance_list)\n",
    "    \n",
    "    result = pd.DataFrame(acc_all, columns = model_list)\n",
    "    result = measure(result,'acc')\n",
    "    \n",
    "    portfolio = pd.DataFrame(balance_all, columns = model_list)\n",
    "    portfolio = measure(portfolio,'portfolio')\n",
    "\n",
    "    return result, portfolio\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86f1e4",
   "metadata": {},
   "source": [
    "## 3. Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b337e9c",
   "metadata": {},
   "source": [
    "### `Part 1: Machine Learning Models`\n",
    "\n",
    "(1) **Logistic Regression**\n",
    "\n",
    "(2) **KNN**\n",
    "\n",
    "(3) **SVM**\n",
    "\n",
    "(4) **Bayes Theorem**\n",
    "\n",
    "(5) **Decision Tree**\n",
    "\n",
    "(6) **Ensemble Methods**\n",
    "\n",
    "* 6.1 Bagging: \n",
    "    * Random Forest\n",
    "    * Bagging Classifier\n",
    "\n",
    "* 6.2 Boosting: \n",
    "    * Gradient Boosting\n",
    "    * AdaBoost\n",
    "    \n",
    "\n",
    "### `Part 2: Deep Learning Models`\n",
    "\n",
    "(7) **CNN (Convolution Neural Networks)**\n",
    "\n",
    "(8) **RNN (Recurrent neural network) and LSTM (Long Short-Term Memory)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee1e58",
   "metadata": {},
   "source": [
    "## 4. Prediction Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dbdd98",
   "metadata": {},
   "source": [
    "### (1) Days to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many days to predict\n",
    "n = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d922a5ef",
   "metadata": {},
   "source": [
    "### (2) Stock tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd826383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ticker_list = pd.read_csv('ticker.csv')['ticker'].tolist()\n",
    "ticker_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e4ccd9",
   "metadata": {},
   "source": [
    "### (3) Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc788c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X: exogenous data\n",
    "exogenous_list = ['Daily_return','5day_return','log_volume','ma_5','BMQ_rto', 'PEQ_rto', 'BEE_rto',\n",
    "       'BAM_rto', 'BCA_rto', 'BER_rto', 'ANL_CHG_rto', 'NIP_rto', 'CSS_rto','MCQ_rto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68469a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = [LogisticRegression(multi_class='multinomial', solver='lbfgs'), \n",
    "                     KNeighborsClassifier(),\n",
    "                     SVC(kernel = 'sigmoid'),\n",
    "                     GaussianNB(),\n",
    "                     DecisionTreeClassifier(max_depth = 2),\n",
    "                     RandomForestClassifier(random_state=1),\n",
    "                     BaggingClassifier(),\n",
    "                     GradientBoostingClassifier(),\n",
    "                     AdaBoostClassifier(),\n",
    "                     \"CNN\",\n",
    "                     \"RNN_LSTM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare accuracy score\n",
    "model_list = [\"ticker\", \"Logistic Regression\", \"KNN\", \"SVM\", \"Bayes Theorem\", \n",
    "              \"Decision Tree\", \"Random Forest\", \"Bagging\", \"Gradient Boost\", \"AdaBoost\", \"CNN\", \"RNN_LSTM\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6900bcb",
   "metadata": {},
   "source": [
    "## 5. Model Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = acc_combine(df, n, ticker_list, exogenous_list, classifier_list, model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c1c25c",
   "metadata": {},
   "source": [
    "### (1) Classification Accruacy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67a758",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc = result[0]\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f88400",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.to_csv('acc_run2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7bf7b2",
   "metadata": {},
   "source": [
    "### (2) Stock Portfolio Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e366e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_return = result[1]\n",
    "stock_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e38817",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_return.to_csv('stock_return_run2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
